{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-19T09:45:01.326976Z","iopub.execute_input":"2021-12-19T09:45:01.327242Z","iopub.status.idle":"2021-12-19T09:45:01.341661Z","shell.execute_reply.started":"2021-12-19T09:45:01.327194Z","shell.execute_reply":"2021-12-19T09:45:01.340504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#6daa9f;\">IMPORTING LIBRARIES</span>**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools\n\nimport tensorflow as tf\nfrom keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.layers import Conv1D, Bidirectional, LSTM, Dense, Input, Dropout, SpatialDropout1D\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n\nimport nltk \nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\n\nimport re\n\nprint(\"Tensorflow Version :\", tf.__version__)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:19:37.494768Z","iopub.execute_input":"2021-12-19T10:19:37.495046Z","iopub.status.idle":"2021-12-19T10:19:37.503043Z","shell.execute_reply.started":"2021-12-19T10:19:37.49501Z","shell.execute_reply":"2021-12-19T10:19:37.502048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#6daa9f;\">LOADING DATA</span>**","metadata":{}},{"cell_type":"code","source":"# Read the data from csv file\ndf = pd.read_csv('../input/sentiment140/training.1600000.processed.noemoticon.csv', encoding = 'latin', header = None)\n\n# Check the data\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:45:08.050172Z","iopub.execute_input":"2021-12-19T09:45:08.050431Z","iopub.status.idle":"2021-12-19T09:45:13.781742Z","shell.execute_reply.started":"2021-12-19T09:45:08.050395Z","shell.execute_reply":"2021-12-19T09:45:13.781047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#6daa9f;\">DATA PREPROCESSING</span>**","metadata":{}},{"cell_type":"markdown","source":"The columns do not have a proper name. Rename them for convinience.","metadata":{}},{"cell_type":"code","source":"# Rename the columns\ndf.columns = ['sentiment', 'id', 'date', 'query', 'user_id', 'text']\n\n# Check data again\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:45:13.782885Z","iopub.execute_input":"2021-12-19T09:45:13.784347Z","iopub.status.idle":"2021-12-19T09:45:13.795967Z","shell.execute_reply.started":"2021-12-19T09:45:13.784308Z","shell.execute_reply":"2021-12-19T09:45:13.795259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are going to trian our data only on text. We can remove rest of the columns from the dataset.","metadata":{}},{"cell_type":"code","source":"# Dropping the unnecessary columns\ndf = df.drop(['id', 'date', 'query', 'user_id'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:45:13.798516Z","iopub.execute_input":"2021-12-19T09:45:13.79894Z","iopub.status.idle":"2021-12-19T09:45:13.844415Z","shell.execute_reply.started":"2021-12-19T09:45:13.798904Z","shell.execute_reply":"2021-12-19T09:45:13.843621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label the sentiment column\nlab_to_sentiment = {0:\"Negative\", 4:\"Positive\"}\ndef label_decoder(label):\n    return lab_to_sentiment[label]\ndf.sentiment = df.sentiment.apply(lambda x: label_decoder(x))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:45:13.845928Z","iopub.execute_input":"2021-12-19T09:45:13.846191Z","iopub.status.idle":"2021-12-19T09:45:14.295913Z","shell.execute_reply.started":"2021-12-19T09:45:13.846158Z","shell.execute_reply":"2021-12-19T09:45:14.295221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check the sentiment data distribution","metadata":{}},{"cell_type":"code","source":"val_count = df.sentiment.value_counts()\n\n# Plot the figure\nplt.figure(figsize = (4,4))\nplt.bar(val_count.index, val_count.values)\nplt.title('Sentiment Data Distribution')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:45:14.297266Z","iopub.execute_input":"2021-12-19T09:45:14.29768Z","iopub.status.idle":"2021-12-19T09:45:14.757057Z","shell.execute_reply.started":"2021-12-19T09:45:14.297643Z","shell.execute_reply":"2021-12-19T09:45:14.756252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observe that the data is balanced","metadata":{}},{"cell_type":"markdown","source":"# **<span style=\"color:#6daa9f;\">TEXT PREPROCESSING</span>**","metadata":{"execution":{"iopub.status.busy":"2021-12-16T14:54:08.736884Z","iopub.execute_input":"2021-12-16T14:54:08.737158Z","iopub.status.idle":"2021-12-16T14:54:08.742082Z","shell.execute_reply.started":"2021-12-16T14:54:08.737097Z","shell.execute_reply":"2021-12-16T14:54:08.741095Z"}}},{"cell_type":"code","source":"stop_words = stopwords.words('english')\nstemmer = SnowballStemmer('english')\ntext_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:45:14.761121Z","iopub.execute_input":"2021-12-19T09:45:14.761462Z","iopub.status.idle":"2021-12-19T09:45:14.77312Z","shell.execute_reply.started":"2021-12-19T09:45:14.761423Z","shell.execute_reply":"2021-12-19T09:45:14.771606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(text, stem=False):\n    text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n    tokens = []\n    for token in text.split():\n        if token not in stop_words:\n            if stem:\n                tokens.append(stemmer.stem(token))\n            else:\n                tokens.append(token)\n    return \" \".join(tokens)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:45:14.777009Z","iopub.execute_input":"2021-12-19T09:45:14.777273Z","iopub.status.idle":"2021-12-19T09:45:14.78681Z","shell.execute_reply.started":"2021-12-19T09:45:14.777241Z","shell.execute_reply":"2021-12-19T09:45:14.785982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.text = df.text.apply(lambda x: preprocess(x))","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:45:14.791172Z","iopub.execute_input":"2021-12-19T09:45:14.793158Z","iopub.status.idle":"2021-12-19T09:46:08.066992Z","shell.execute_reply.started":"2021-12-19T09:45:14.793102Z","shell.execute_reply":"2021-12-19T09:46:08.066249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:46:08.06845Z","iopub.execute_input":"2021-12-19T09:46:08.068697Z","iopub.status.idle":"2021-12-19T09:46:08.078638Z","shell.execute_reply.started":"2021-12-19T09:46:08.068666Z","shell.execute_reply":"2021-12-19T09:46:08.077967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data is now **cleaned**","metadata":{}},{"cell_type":"markdown","source":"# **<span style=\"color:#6daa9f;\">TRAIN AND TEST SPLIT</span>**","metadata":{}},{"cell_type":"code","source":"# Define some constants\ntrain_size = 0.8\nmax_nb_words = 100000\nmax_sequence_length = 30","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:46:08.079766Z","iopub.execute_input":"2021-12-19T09:46:08.080478Z","iopub.status.idle":"2021-12-19T09:46:08.088544Z","shell.execute_reply.started":"2021-12-19T09:46:08.080421Z","shell.execute_reply":"2021-12-19T09:46:08.087819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and testing data\ntrain_data, test_data = train_test_split(df, test_size = 1 - train_size, random_state = 7)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:46:08.089927Z","iopub.execute_input":"2021-12-19T09:46:08.090231Z","iopub.status.idle":"2021-12-19T09:46:08.604234Z","shell.execute_reply.started":"2021-12-19T09:46:08.090178Z","shell.execute_reply":"2021-12-19T09:46:08.60349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the training and testing data size\nprint(\"Train data size : \", len(train_data))\nprint(\"Test data size : \", len(test_data))","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:46:08.608009Z","iopub.execute_input":"2021-12-19T09:46:08.608303Z","iopub.status.idle":"2021-12-19T09:46:08.614819Z","shell.execute_reply.started":"2021-12-19T09:46:08.608271Z","shell.execute_reply":"2021-12-19T09:46:08.613866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the training data\ntrain_data.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:46:08.616736Z","iopub.execute_input":"2021-12-19T09:46:08.617447Z","iopub.status.idle":"2021-12-19T09:46:08.628836Z","shell.execute_reply.started":"2021-12-19T09:46:08.617409Z","shell.execute_reply":"2021-12-19T09:46:08.627466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#6daa9f;\">TOKENIZATION</span>**","metadata":{"execution":{"iopub.status.busy":"2021-12-16T15:19:02.107929Z","iopub.execute_input":"2021-12-16T15:19:02.108297Z","iopub.status.idle":"2021-12-16T15:19:02.113318Z","shell.execute_reply.started":"2021-12-16T15:19:02.108255Z","shell.execute_reply":"2021-12-16T15:19:02.112378Z"}}},{"cell_type":"code","source":"# Creates tokens for every word and maps them to an index using dictionary\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(train_data.text)\n\n# Contains the index for each word\nword_index = tokenizer.word_index\n\n# Represents the total number of words in the data corpus\nvocab_size = len(tokenizer.word_index) + 1","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:46:08.631058Z","iopub.execute_input":"2021-12-19T09:46:08.6316Z","iopub.status.idle":"2021-12-19T09:46:26.368614Z","shell.execute_reply.started":"2021-12-19T09:46:08.631561Z","shell.execute_reply":"2021-12-19T09:46:26.367856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:46:26.370004Z","iopub.execute_input":"2021-12-19T09:46:26.370281Z","iopub.status.idle":"2021-12-19T09:46:26.37438Z","shell.execute_reply.started":"2021-12-19T09:46:26.370246Z","shell.execute_reply":"2021-12-19T09:46:26.373595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = pad_sequences(tokenizer.texts_to_sequences(train_data.text), maxlen = max_sequence_length)\nX_test = pad_sequences(tokenizer.texts_to_sequences(test_data.text), maxlen = max_sequence_length)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:46:26.375916Z","iopub.execute_input":"2021-12-19T09:46:26.37625Z","iopub.status.idle":"2021-12-19T09:46:56.392723Z","shell.execute_reply.started":"2021-12-19T09:46:26.376194Z","shell.execute_reply":"2021-12-19T09:46:56.391977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Traning X shape : \", X_train.shape)\nprint(\"Testing X shape : \", X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:46:56.393813Z","iopub.execute_input":"2021-12-19T09:46:56.394057Z","iopub.status.idle":"2021-12-19T09:46:56.403327Z","shell.execute_reply.started":"2021-12-19T09:46:56.394025Z","shell.execute_reply":"2021-12-19T09:46:56.402345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = train_data.sentiment.unique().tolist()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:46:56.404602Z","iopub.execute_input":"2021-12-19T09:46:56.40541Z","iopub.status.idle":"2021-12-19T09:46:56.512706Z","shell.execute_reply.started":"2021-12-19T09:46:56.405372Z","shell.execute_reply":"2021-12-19T09:46:56.512007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **<span style=\"color:#6daa9f;\">LABEL ENCODING</span>**","metadata":{}},{"cell_type":"code","source":"encoder = LabelEncoder()\nencoder.fit(train_data.sentiment.to_list())\n\ny_train = encoder.transform(train_data.sentiment.to_list())\ny_test = encoder.transform(test_data.sentiment.to_list())\n\ny_train = y_train.reshape(-1,1)\ny_test = y_test.reshape(-1,1)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:46:56.513802Z","iopub.execute_input":"2021-12-19T09:46:56.514063Z","iopub.status.idle":"2021-12-19T09:46:57.651524Z","shell.execute_reply.started":"2021-12-19T09:46:56.514028Z","shell.execute_reply":"2021-12-19T09:46:57.650787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"y_test shape : \", y_test.shape)\nprint(\"y_train shape : \", y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:46:57.652625Z","iopub.execute_input":"2021-12-19T09:46:57.652868Z","iopub.status.idle":"2021-12-19T09:46:57.659892Z","shell.execute_reply.started":"2021-12-19T09:46:57.652836Z","shell.execute_reply":"2021-12-19T09:46:57.659107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#6daa9f;\">WORD EMBEDDING</span>**","metadata":{}},{"cell_type":"code","source":"!wget http://nlp.stanford.edu/data/glove.6B.zip\n!unzip glove.6B.zip","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:46:57.661475Z","iopub.execute_input":"2021-12-19T09:46:57.662101Z","iopub.status.idle":"2021-12-19T09:50:02.801238Z","shell.execute_reply.started":"2021-12-19T09:46:57.662062Z","shell.execute_reply":"2021-12-19T09:50:02.800338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GLOVE_EMB = '/kaggle/working/glove.6B.300d.txt'\nEMBEDDING_DIM = 300\nLR = 1e-3\nBATCH_SIZE = 1024\nEPOCHS = 10\nMODEL_PATH = '.../output/kaggle/working/best_model.hdf5'","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:50:02.803827Z","iopub.execute_input":"2021-12-19T09:50:02.80426Z","iopub.status.idle":"2021-12-19T09:50:02.809229Z","shell.execute_reply.started":"2021-12-19T09:50:02.804177Z","shell.execute_reply":"2021-12-19T09:50:02.808424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings_index = {}\nf = open(GLOVE_EMB)\nfor line in f:\n    values = line.split()\n    word = value = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\nprint('Found %s word vectors.' %len(embeddings_index))","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:50:02.810872Z","iopub.execute_input":"2021-12-19T09:50:02.811402Z","iopub.status.idle":"2021-12-19T09:50:47.417064Z","shell.execute_reply.started":"2021-12-19T09:50:02.811364Z","shell.execute_reply":"2021-12-19T09:50:47.416276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:50:47.418625Z","iopub.execute_input":"2021-12-19T09:50:47.419071Z","iopub.status.idle":"2021-12-19T09:50:47.896493Z","shell.execute_reply.started":"2021-12-19T09:50:47.419034Z","shell.execute_reply":"2021-12-19T09:50:47.895721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_layer = tf.keras.layers.Embedding(vocab_size, EMBEDDING_DIM, weights = [embedding_matrix], input_length = max_sequence_length, trainable = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:50:47.897742Z","iopub.execute_input":"2021-12-19T09:50:47.899378Z","iopub.status.idle":"2021-12-19T09:50:47.93028Z","shell.execute_reply.started":"2021-12-19T09:50:47.899337Z","shell.execute_reply":"2021-12-19T09:50:47.929447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#6daa9f;\">MODEL TRAINING - LSTM</span>**","metadata":{}},{"cell_type":"code","source":"# Build the model\nsequence_input = Input(shape = max_sequence_length, dtype = 'int32')\nembedding_sequences = embedding_layer(sequence_input)\nx = SpatialDropout1D(0.2)(embedding_sequences)\nx = Conv1D(65, 5, activation = 'relu')(x)\nx = Bidirectional(LSTM(64, dropout = 0.2,recurrent_dropout = 0.2))(x)\nx = Dense(512, activation = 'relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation = 'relu')(x)\noutputs = Dense(1, activation = 'sigmoid')(x)\nmodel = tf.keras.Model(sequence_input, outputs)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:50:47.931395Z","iopub.execute_input":"2021-12-19T09:50:47.931842Z","iopub.status.idle":"2021-12-19T09:50:51.328948Z","shell.execute_reply.started":"2021-12-19T09:50:47.931806Z","shell.execute_reply":"2021-12-19T09:50:51.328233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer = Adam(learning_rate = LR),\n             loss = 'binary_crossentropy',\n             metrics = ['accuracy'])\nReduceLROnPlateau = ReduceLROnPlateau(factor = 0.1,\n                                   min_lr = 0.01,\n                                   monitor = 'val_loss',\n                                   verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:50:51.330367Z","iopub.execute_input":"2021-12-19T09:50:51.330665Z","iopub.status.idle":"2021-12-19T09:50:51.343811Z","shell.execute_reply.started":"2021-12-19T09:50:51.330629Z","shell.execute_reply":"2021-12-19T09:50:51.342987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the model\nhistory = model.fit(X_train, y_train, batch_size = BATCH_SIZE, epochs = EPOCHS, validation_data = (X_test, y_test),\n                   callbacks = [ReduceLROnPlateau])","metadata":{"execution":{"iopub.status.busy":"2021-12-19T09:55:38.199757Z","iopub.execute_input":"2021-12-19T09:55:38.200081Z","iopub.status.idle":"2021-12-19T10:18:03.110173Z","shell.execute_reply.started":"2021-12-19T09:55:38.200046Z","shell.execute_reply":"2021-12-19T10:18:03.109374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#6daa9f;\">MODEL EVALUATION</span>**","metadata":{}},{"cell_type":"markdown","source":"Plot the learning curve of loss and accuracy with each epoch","metadata":{}},{"cell_type":"code","source":"s, (at,al) = plt.subplots(2,1)\nat.plot(history.history['accuracy'],c = 'b')\nat.plot(history.history['val_accuracy'], c = 'r')\nat.set_title('Model accuracy')\nat.set_ylabel('Accuracy')\nat.set_xlabel('Epoch')\nat.legend(['LSTM_train', 'LSTM_val'], loc = 'upper left')\n\nal.plot(history.history['loss'], c='m')\nal.plot(history.history['val_loss'], c='c')\nal.set_title('Model loss')\nal.set_ylabel('Loss')\nal.set_xlabel('Epoch')\nal.legend(['train','val'], loc = 'upper left')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:19:30.458827Z","iopub.execute_input":"2021-12-19T10:19:30.459284Z","iopub.status.idle":"2021-12-19T10:19:30.760367Z","shell.execute_reply.started":"2021-12-19T10:19:30.459249Z","shell.execute_reply":"2021-12-19T10:19:30.759713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model will output a prediction score between 0 and 1. We can classiy two classes by defining a threshold value for it.\nIn this case, we are going to set the threshold vaule to 0.5. If the score is **above 0.5**, then it will be classified as **positive** sentiment.","metadata":{}},{"cell_type":"code","source":"def decode_sentiment(score):\n    return 'Positive' if score > 0.5 else 'Negative'","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:20:07.108611Z","iopub.execute_input":"2021-12-19T10:20:07.108872Z","iopub.status.idle":"2021-12-19T10:20:07.113572Z","shell.execute_reply.started":"2021-12-19T10:20:07.10884Z","shell.execute_reply":"2021-12-19T10:20:07.112589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = model.predict(X_test, verbose = 1, batch_size = 10000)\ny_pred_1d = [decode_sentiment(score) for score in scores ]","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:20:15.414006Z","iopub.execute_input":"2021-12-19T10:20:15.414349Z","iopub.status.idle":"2021-12-19T10:20:18.063821Z","shell.execute_reply.started":"2021-12-19T10:20:15.41431Z","shell.execute_reply":"2021-12-19T10:20:18.06307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Confusion Matrix","metadata":{}},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, fontsize=20)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, fontsize=13)\n    plt.yticks(tick_marks, classes, fontsize=13)\n\n    fmt = '.2f'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label', fontsize=17)\n    plt.xlabel('Predicted label', fontsize=17)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:20:32.600855Z","iopub.execute_input":"2021-12-19T10:20:32.601114Z","iopub.status.idle":"2021-12-19T10:20:32.61202Z","shell.execute_reply.started":"2021-12-19T10:20:32.601086Z","shell.execute_reply":"2021-12-19T10:20:32.611246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnf_matrix = confusion_matrix(test_data.sentiment.to_list(), y_pred_1d)\nplt.figure(figsize=(6,6))\nplot_confusion_matrix(cnf_matrix, classes=test_data.sentiment.unique(), title=\"Confusion matrix\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:20:36.527955Z","iopub.execute_input":"2021-12-19T10:20:36.52862Z","iopub.status.idle":"2021-12-19T10:20:38.239817Z","shell.execute_reply.started":"2021-12-19T10:20:36.528581Z","shell.execute_reply":"2021-12-19T10:20:38.239143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(list(test_data.sentiment), y_pred_1d))","metadata":{"execution":{"iopub.status.busy":"2021-12-19T10:20:41.021728Z","iopub.execute_input":"2021-12-19T10:20:41.022345Z","iopub.status.idle":"2021-12-19T10:20:45.315459Z","shell.execute_reply.started":"2021-12-19T10:20:41.022305Z","shell.execute_reply":"2021-12-19T10:20:45.313863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}